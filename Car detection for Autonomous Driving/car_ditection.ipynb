{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91aa9d64",
   "metadata": {},
   "source": [
    "# car ditection using YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170877c2",
   "metadata": {},
   "source": [
    "# import modul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "175a57c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 22:15:45.354348: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-06 22:15:45.354499: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-06 22:15:45.357933: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-06 22:15:45.374154: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-06 22:15:46.957085: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Lambda, Conv2D\n",
    "from keras.models import load_model, Model\n",
    "from yolo_utils import read_classes, read_anchors, generate_colors, preprocess_image, draw_boxes, scale_boxes\n",
    "from yad2k.models.keras_yolo import yolo_head, yolo_boxes_to_corners, preprocess_true_boxes, yolo_loss, yolo_body\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a0dcac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering with a threshold on class scores\n",
    "def yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold=0.6):\n",
    "    # Step 1: Compute box scores\n",
    "    box_scores = box_confidence * box_class_probs\n",
    "\n",
    "    # Step 2: Find the box_classes using the max box_scores, keep track of the corresponding score\n",
    "    box_classes = tf.argmax(box_scores, axis=-1)\n",
    "    box_class_scores = tf.reduce_max(box_scores, axis=-1)\n",
    "\n",
    "    # Step 3: Create a filtering mask based on \"box_class_scores\" by using \"threshold\"\n",
    "    filtering_mask = box_class_scores >= threshold\n",
    "\n",
    "    # Step 4: Apply the mask to box_class_scores, boxes, and box_classes\n",
    "    scores = tf.boolean_mask(box_class_scores, filtering_mask)\n",
    "    filtered_boxes = tf.boolean_mask(boxes, filtering_mask)\n",
    "    classes = tf.boolean_mask(box_classes, filtering_mask)\n",
    "\n",
    "    return scores, filtered_boxes, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5651591",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_confidence = tf.random.normal([19, 19, 5, 1], mean=1, stddev=4, seed=1)\n",
    "boxes = tf.random.normal([19, 19, 5, 4], mean=1, stddev=4, seed=1)\n",
    "box_class_probs = tf.random.normal([19, 19, 5, 80], mean=1, stddev=4, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5123589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the filter\n",
    "scores, filtered_boxes, classes = yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0d70377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [21.294851 62.658787 16.064978 ... 33.62834  54.689083 58.749218]\n",
      "filtered_boxes: [[ 2.88381     2.9140406  -0.03477657  2.7024395 ]\n",
      " [ 4.01801     7.102514   -1.421094   -1.1415017 ]\n",
      " [ 1.0273384  -2.1178942   4.8872733  -4.0143332 ]\n",
      " ...\n",
      " [-0.27290797  7.283095    5.799567   -1.5821693 ]\n",
      " [-0.98508644 -2.4997838   7.1540446  -5.151011  ]\n",
      " [ 8.872453   -0.37440765  0.8893236   3.25239   ]]\n",
      "classes: [32 73 78 ... 15 73 44]\n"
     ]
    }
   ],
   "source": [
    "print(\"scores:\", scores.numpy())\n",
    "print(\"filtered_boxes:\", filtered_boxes.numpy())\n",
    "print(\"classes:\", classes.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907755f3",
   "metadata": {},
   "source": [
    "# Non-max suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2be617a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(box1, box2):\n",
    "   \n",
    "\n",
    "    # Assign variable names to coordinates for clarity\n",
    "    (box1_x1, box1_y1, box1_x2, box1_y2) = box1\n",
    "    (box2_x1, box2_y1, box2_x2, box2_y2) = box2\n",
    "    \n",
    "    # Calculate the (xi1, yi1, xi2, yi2) coordinates of the intersection of box1 and box2\n",
    "    xi1 = max(box1_x1, box2_x1)\n",
    "    yi1 = max(box1_y1, box2_y1)\n",
    "    xi2 = min(box1_x2, box2_x2)\n",
    "    yi2 = min(box1_y2, box2_y2)\n",
    "    \n",
    "    # Calculate the width and height of the intersection\n",
    "    inter_width = max(xi2 - xi1, 0)\n",
    "    inter_height = max(yi2 - yi1, 0)\n",
    "    \n",
    "    # Calculate the area of the intersection\n",
    "    inter_area = inter_width * inter_height\n",
    "    \n",
    "    # Calculate the area of both bounding boxes\n",
    "    box1_area = (box1_x2 - box1_x1) * (box1_y2 - box1_y1)\n",
    "    box2_area = (box2_x2 - box2_x1) * (box2_y2 - box2_y1)\n",
    "    \n",
    "    # Calculate the union area\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    \n",
    "    # Compute the IoU\n",
    "    iou = inter_area / union_area\n",
    "    \n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3581b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iou for intersecting boxes = 0.14285714285714285\n",
      "iou for non-intersecting boxes = 0.0\n",
      "iou for boxes that only touch at vertices = 0.0\n",
      "iou for boxes that only touch at edges = 0.0\n"
     ]
    }
   ],
   "source": [
    "## Test case 1: boxes intersect\n",
    "box1 = (2, 1, 4, 3)\n",
    "box2 = (1, 2, 3, 4) \n",
    "print(\"iou for intersecting boxes = \" + str(iou(box1, box2)))\n",
    "\n",
    "## Test case 2: boxes do not intersect\n",
    "box1 = (1,2,3,4)\n",
    "box2 = (5,6,7,8)\n",
    "print(\"iou for non-intersecting boxes = \" + str(iou(box1,box2)))\n",
    "\n",
    "## Test case 3: boxes intersect at vertices only\n",
    "box1 = (1,1,2,2)\n",
    "box2 = (2,2,3,3)\n",
    "print(\"iou for boxes that only touch at vertices = \" + str(iou(box1,box2)))\n",
    "\n",
    "## Test case 4: boxes intersect at edge only\n",
    "box1 = (1,1,3,3)\n",
    "box2 = (2,3,3,4)\n",
    "print(\"iou for boxes that only touch at edges = \" + str(iou(box1,box2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82648d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_non_max_suppression(scores, boxes, classes, max_boxes=10, iou_threshold=0.5):\n",
    "    \n",
    "    \n",
    "    # Ensure max_boxes is a tensor for tf.image.non_max_suppression\n",
    "    max_boxes_tensor = tf.Variable(max_boxes, dtype='int32')\n",
    "    \n",
    "    # Use tf.image.non_max_suppression() to get the list of indices corresponding to boxes you keep\n",
    "    nms_indices = tf.image.non_max_suppression(boxes, scores, max_output_size=max_boxes, iou_threshold=iou_threshold)\n",
    "    \n",
    "    # Use tf.gather() to select only nms_indices from scores, boxes and classes\n",
    "    scores = tf.gather(scores, nms_indices)\n",
    "    boxes = tf.gather(boxes, nms_indices)\n",
    "    classes = tf.gather(classes, nms_indices)\n",
    "    \n",
    "    return scores, boxes, classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15bbdbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores[2] = 6.082263\n",
      "boxes[2] = [ 4.110873   2.544206   2.1469054 -1.5198021]\n",
      "classes[2] = 5.049652\n",
      "scores.shape = (10,)\n",
      "boxes.shape = (10, 4)\n",
      "classes.shape = (10,)\n"
     ]
    }
   ],
   "source": [
    "scores = tf.random.normal([54,], mean=1, stddev=4, seed = 1)\n",
    "boxes =tf.random.normal([54, 4], mean=1, stddev=4, seed = 1)\n",
    "classes =tf.random.normal([54,], mean=1, stddev=4, seed = 1)\n",
    "scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes)\n",
    "print(\"scores[2] = \" + str(scores[2].numpy()))\n",
    "print(\"boxes[2] = \" + str(boxes[2].numpy()))\n",
    "print(\"classes[2] = \" + str(classes[2].numpy()))\n",
    "print(\"scores.shape = \" + str(scores.numpy().shape))\n",
    "print(\"boxes.shape = \" + str(boxes.numpy().shape))\n",
    "print(\"classes.shape = \" + str(classes.numpy().shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867b5c08",
   "metadata": {},
   "source": [
    "# Wrapping up the filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e556790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_boxes_to_corners(box_xy, box_wh):\n",
    "    \"\"\"\n",
    "    Convert YOLO box predictions to bounding box corners.\n",
    "    Arguments:\n",
    "    box_xy -- tensor of shape (None, 19, 19, 5, 2)\n",
    "    box_wh -- tensor of shape (None, 19, 19, 5, 2)\n",
    "    Returns:\n",
    "    boxes -- tensor of shape (None, 19, 19, 5, 4)\n",
    "    \"\"\"\n",
    "    box_mins = box_xy - (box_wh / 2.)\n",
    "    box_maxes = box_xy + (box_wh / 2.)\n",
    "\n",
    "    return tf.concat([box_mins[..., 1:2], box_mins[..., 0:1], box_maxes[..., 1:2], box_maxes[..., 0:1]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "328599ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_boxes(boxes, image_shape):\n",
    "    \"\"\"\n",
    "    Scales the predicted boxes in order to be drawable on the image\n",
    "    Arguments:\n",
    "    boxes -- tensor of shape (None, 4) containing the coordinates of the boxes\n",
    "    image_shape -- tensor of shape (2,) containing the shape of the image\n",
    "    Returns:\n",
    "    boxes -- tensor of shape (None, 4) containing the scaled coordinates of the boxes\n",
    "    \"\"\"\n",
    "    height, width = image_shape\n",
    "    image_dims = tf.stack([height, width, height, width])\n",
    "    image_dims = tf.cast(image_dims, tf.float32)\n",
    "    return boxes * image_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7fdb4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_eval(yolo_outputs, image_shape=(720., 1280.), max_boxes=10, score_threshold=.6, iou_threshold=.5):\n",
    "    \"\"\"\n",
    "    Converts the output of YOLO encoding (a lot of boxes) to your predicted boxes along with their scores, box coordinates, and classes.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve outputs of the YOLO model\n",
    "    box_confidence, box_xy, box_wh, box_class_probs = yolo_outputs\n",
    "\n",
    "    # Convert boxes to be ready for filtering functions\n",
    "    boxes = yolo_boxes_to_corners(box_xy, box_wh)\n",
    "\n",
    "    # Perform Score-filtering with a threshold of score_threshold\n",
    "    scores, boxes, classes = yolo_filter_boxes(box_confidence, boxes, box_class_probs, score_threshold)\n",
    "    \n",
    "    # Scale boxes back to original image shape\n",
    "    boxes = scale_boxes(boxes, image_shape)\n",
    "\n",
    "    # Perform Non-max suppression\n",
    "    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes, max_boxes, iou_threshold)\n",
    "    \n",
    "    return scores, boxes, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0f40ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores[2] = 147.72488\n",
      "boxes[2] = [2651.31   1417.04   1748.9335 7298.7256]\n",
      "classes[2] = 74\n",
      "scores.shape = (10,)\n",
      "boxes.shape = (10, 4)\n",
      "classes.shape = (10,)\n"
     ]
    }
   ],
   "source": [
    "yolo_outputs = ( tf.random.normal([19, 19, 5, 1], mean=1, stddev=4, seed = 1),\n",
    "                     tf.random.normal([19, 19, 5, 2], mean=1, stddev=4, seed = 1),\n",
    "                     tf.random.normal([19, 19, 5, 2], mean=1, stddev=4, seed = 1),\n",
    "                     tf.random.normal([19, 19, 5, 80], mean=1, stddev=4, seed = 1))\n",
    "scores, boxes, classes = yolo_eval(yolo_outputs)\n",
    "print(\"scores[2] = \" + str(scores[2].numpy()))\n",
    "print(\"boxes[2] = \" + str(boxes[2].numpy()))\n",
    "print(\"classes[2] = \" + str(classes[2].numpy()))\n",
    "print(\"scores.shape = \" + str(scores.numpy().shape))\n",
    "print(\"boxes.shape = \" + str(boxes.numpy().shape))\n",
    "print(\"classes.shape = \" + str(classes.numpy().shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb33c475",
   "metadata": {},
   "source": [
    "# Test YOLO pre-trained model on images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff217bb6",
   "metadata": {},
   "source": [
    "Defining classes, anchors and image shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79756911",
   "metadata": {},
   "source": [
    "Loading a pre-trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "037fb299",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at model_data/yolo.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m yolo_model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_data/yolo.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/saving_api.py:262\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    255\u001b[0m         filepath,\n\u001b[1;32m    256\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[1;32m    258\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    263\u001b[0m     filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    264\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/legacy/save.py:234\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[0;32m--> 234\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[1;32m    235\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    236\u001b[0m         )\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m    240\u001b[0m             filepath_str, \u001b[38;5;28mcompile\u001b[39m, options\n\u001b[1;32m    241\u001b[0m         )\n",
      "\u001b[0;31mOSError\u001b[0m: No file or directory found at model_data/yolo.h5"
     ]
    }
   ],
   "source": [
    "yolo_model = load_model(\"model_data/yolo.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3ea776",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
